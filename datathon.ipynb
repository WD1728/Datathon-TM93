{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54551ac-0ba7-4134-8f68-3c7c5f913297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 193, 'name': 'Cardiotocography', 'repository_url': 'https://archive.ics.uci.edu/dataset/193/cardiotocography', 'data_url': 'https://archive.ics.uci.edu/static/public/193/data.csv', 'abstract': 'The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 2126, 'num_features': 21, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['CLASS', 'NSP'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2000, 'last_updated': 'Fri Mar 15 2024', 'dataset_doi': '10.24432/C51S4N', 'creators': ['D. Campos', 'J. Bernardes'], 'intro_paper': None, 'additional_info': {'summary': '2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'LB - FHR baseline (beats per minute)\\r\\nAC - # of accelerations per second\\r\\nFM - # of fetal movements per second\\r\\nUC - # of uterine contractions per second\\r\\nDL - # of light decelerations per second\\r\\nDS - # of severe decelerations per second\\r\\nDP - # of prolongued decelerations per second\\r\\nASTV - percentage of time with abnormal short term variability\\r\\nMSTV - mean value of short term variability\\r\\nALTV - percentage of time with abnormal long term variability\\r\\nMLTV - mean value of long term variability\\r\\nWidth - width of FHR histogram\\r\\nMin - minimum of FHR histogram\\r\\nMax - Maximum of FHR histogram\\r\\nNmax - # of histogram peaks\\r\\nNzeros - # of histogram zeros\\r\\nMode - histogram mode\\r\\nMean - histogram mean\\r\\nMedian - histogram median\\r\\nVariance - histogram variance\\r\\nTendency - histogram tendency\\r\\nCLASS - FHR pattern class code (1 to 10) \\r\\nNSP - fetal state class code (N=normal; S=suspect; P=pathologic)', 'citation': None}}\n",
      "        name     role        type demographic description units missing_values\n",
      "0         LB  Feature     Integer        None        None  None             no\n",
      "1         AC  Feature  Continuous        None        None  None             no\n",
      "2         FM  Feature  Continuous        None        None  None             no\n",
      "3         UC  Feature  Continuous        None        None  None             no\n",
      "4         DL  Feature  Continuous        None        None  None             no\n",
      "5         DS  Feature  Continuous        None        None  None             no\n",
      "6         DP  Feature  Continuous        None        None  None             no\n",
      "7       ASTV  Feature     Integer        None        None  None             no\n",
      "8       MSTV  Feature  Continuous        None        None  None             no\n",
      "9       ALTV  Feature     Integer        None        None  None             no\n",
      "10      MLTV  Feature  Continuous        None        None  None             no\n",
      "11     Width  Feature     Integer        None        None  None             no\n",
      "12       Min  Feature     Integer        None        None  None             no\n",
      "13       Max  Feature     Integer        None        None  None             no\n",
      "14      Nmax  Feature     Integer        None        None  None             no\n",
      "15    Nzeros  Feature     Integer        None        None  None             no\n",
      "16      Mode  Feature     Integer        None        None  None             no\n",
      "17      Mean  Feature     Integer        None        None  None             no\n",
      "18    Median  Feature     Integer        None        None  None             no\n",
      "19  Variance  Feature     Integer        None        None  None             no\n",
      "20  Tendency  Feature     Integer        None        None  None             no\n",
      "21     CLASS   Target     Integer        None        None  None             no\n",
      "22       NSP   Target     Integer        None        None  None             no\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from typing import Dict, Tuple, List\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import check_X_y\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    _HAS_IMB = True\n",
    "except Exception:\n",
    "    _HAS_IMB = False\n",
    "\n",
    "#import dataset\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "cardiotocography = fetch_ucirepo(id=193) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = cardiotocography.data.features \n",
    "y = cardiotocography.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(cardiotocography.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(cardiotocography.variables) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a2146e-002c-4699-85cd-582bc9012902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning and Preprocessing\n",
    "\n",
    "df = pd.concat([X.reset_index(drop=True), \n",
    "                y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#Check missing values\n",
    "missing_total = df.isnull().sum().sum()\n",
    "print(\"Number of missing values:\", missing_total)\n",
    "\n",
    "#preprocess function\n",
    "def preprocess_ctg(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: List[str] = \"NSP\",\n",
    "    drop_cols: List[str] = [\"DR\"],  # drop DR, p=1\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 3407,\n",
    "    use_smote: bool = True\n",
    ") -> Dict[str, object]:\n",
    "    \n",
    "\n",
    "    # 1. select features\n",
    "    feature_cols = [c for c in df.columns if c not in drop_cols + target_col]\n",
    "    X = df[feature_cols].to_numpy()\n",
    "    \n",
    "    # 2. encode labels (for scikit-learn classifier)\n",
    "    y_raw = df[target_col].to_numpy()\n",
    "    if np.array_equal(np.unique(y_raw), np.array([1, 2, 3])):\n",
    "        y = y_raw.astype(int) - 1\n",
    "    else:\n",
    "        _, y = np.unique(y_raw, return_inverse=True)\n",
    "\n",
    "    # 3. stratified split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    \n",
    "    #4. scale (train-fit, test-transform)\n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    X_te = scaler.transform(X_te)\n",
    "\n",
    "    #5. SMOTE (only on training set) \n",
    "    \"\"\"\n",
    "    We decide to use SMOTE since the number of type \"normal\"(1655) is much bigger than \"Suspect\"(295) and \"Pathologic\"(176)\n",
    "    but S and P are equally or even more important in real medical analysis. \n",
    "    \n",
    "    \"\"\"\n",
    "    if use_smote:\n",
    "        sm = SMOTE(random_state=random_state)\n",
    "        X_tr, y_tr = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_tr,\n",
    "        \"y_train\": y_tr,\n",
    "        \"X_test\": X_te,\n",
    "        \"y_test\": y_te,\n",
    "        \"scaler\": scaler,\n",
    "        \"feature_names\": feature_cols,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada80bf7-95ef-4597-a320-3f8d4c001956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c1d94-99fa-4a88-bcd6-417fd698f51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
